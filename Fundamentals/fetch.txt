
Despite the name, this will be a collection of notes pertaining
to a variety of things that are low level

Core Dumped:

  Core dumped refers to the displacement of an active process' execution context
  (it's memory usage, program counter, stack pointer and so on) to a file
  on abnormal termination.

Fetch Execute Cycle:

  First note the following components involved:

  Units and Registers:

    MAR (Memory Address Register):
    
      The memory address register holds the address of the next value to be
      read from main memory.

    MDR (Memory Data Register):

      This is a two way register; data is both read and written to it.

      On read, the data addressed by the location in the MAR is used to
      populate the MDR.

      On write, data in the data in the MDR is written to the location in the MAR 
      corresponding to some point in the main memory.

    CC (Control Unit):

      The CC manages the coordination of the CPU; coordinates communications
      between I/o devices and other units, including their timing and the
      signals sent to them.

    PC (Program Counter):

      The program counter contains the address of the next instruction to be
      executed by the control unit.

    IR (Instruction Register):

      The instruction register holds the data representing the CPU instruction.

      The instruction register is typically split into two parts; we call them
      IR(OP) and IR(ADDR).

  Operations of the fetch execute cycle.

    The PC is set to contain the address of the next instruction; this is then copied
    into the MAR.

    The CPU does this by sending a read request, through the control
    bus, to the RAM, to tell the RAM to return the address
    currently being pointed to by the PC, passing the relevant address through
    the address register.

    The data within RAM referred to by the MAR is then placed
    within the MDR, being passed through to it on the data bus, then
    to the IR through the same means if the data is an opcode; it's not immediately 
    copied to the instruction register because it may be another kind of data.
    The load command is an example of such an instance of varying data.

    It should be noted that the value within the instruction register is segmented
    being composed of one IR(OP) opcode segment, and at most two IR(ADDR)
    address segments.
    
    The most significant bits tend to compose the opcode, the least being
    the addresses.

    The IR(OP) segment of the instruction is then ultimately decoded by the CC, with the
    PC then being incremented by one.

    Overview:

      1. MAR <- PC
      2. MDR <- <MAR>
      3.  IR <- MDR
      4.  PC <- PC + 1

    Suppose that the opcode represented by IR(OP) was LOAD <A>, B; this corresponds
    to loading the accumulator with the value B at the address <A>.
    
    The IR(ADDR) portion(s) of the value within the instruction register corresponds to
    an operand, which is a value used in an operation.

    With the LOAD example, LOAD <A>, B has the following register usage:

      1. MAR <- IR(ADDR)
      2. MDR <- <MAR>
      3.  AC <- MDR # Now we know its data.

DMA:

  DMA is an acronym for 'direct memory access.' It allows
  hardware to access main system memory independently to
  the CPU.

  With DMA, the CPU first initiates the transfer,
  then performs other tasks with the transfer in progress,
  then an interrupt to the CPU from the DMA controller
  tells the CPU that the operation is finished.

  This is useful if the CPU cannot keep up with the
  rate of the data transfer, or when the CPU needs to
  perform work while waiting for a slow I/o transfer.

  The idea of DMA could lead to cache coherency problems.

  For example, if a CPU reads a value X in memory,
  subsequent versions of X will be appended to the
  cache; if the DMA controller makes an access to X
  for a component of the computer, and the cached value
  hasn't been flushed to the main memory, the
  DMA controller will read a stale value.

CPU Cache:

  A cache is a hardware component that stores
  data so future requests for that data
  can be served faster; a cache hit occurs when
  the requested data can be found within the cache,
  a cache miss if not.

  The cache is typically implemented using static
  random access memory, which uses a latching mechanism
  to store each bit of information. This memory
  doesn't require to be refreshed, unlike DRAM.

  There is a trade-off between size and speed in
  the process of designing memory: a larger size makes
  signals travel larger physical distances, causing
  delay.

  The buffer provided by a cache benefits the
  problems with latency and throughput; it could take
  hundreds of clock cycles before a modern four giga
  hurtz processor reaches DRAM.

Address bus:

  The address bus is used to specify a memory
  address; when the processor or a DMA
  device reads or writes to an address, that address
  is specified on the address bus.

Data bus:

  The data bus is used to transfer data to and from each
  component of the computer.

  The bandwidth is the capacity of the bus, specifying
  the amount of data.

Control bus:

  This is used to coordinate, send signals, to other
  devices within the computer.

  While the function is similar to the other buses,
  this is used to carry commands to the CPU.

  It also allows devices to return signals to the
  CPU, to communicate the state of the device.

Volatile Memory:

  Volatile memory means that data in this memory gets destroyed on shutdown; it
  is subject to change.

Mutability:

  Mutability determines an objects ability to be altered; mutable memory can
  be accessed and changed.

  Mutable does strictly make it volatile through; they mean different things
  in the context. Memory is volatile if its state is reset on shutdown,
  mutable if it can be altered to contain different values, have variant state.

Static Ram:

  This is a type of ram that uses latching circuitry; uses flip flops.

  SRAM is often more  expensive than DRAM in terms of silicon usage, being both 
  faster and not requiring to be periodically refreshed.

  The reason for the expense is partially due to the requirement of more
  transistors.

  This is typically how the cpu cache is implemented.

Dynamic Ram:

  The defining characteristic of DRAM is that it requires to be refreshed.

  This is because each bit of memory is stored as an electrical charge within
  a small capacitor on the chip; with the passage of time, the charge
  in the memory cell dissipates away.

  Consequently, this means we need to refresh the memory constantly, to
  prevent the memory from decaying over time; this is where the
  memory speed metric for enterprise memory derives in hurtz.

  The overhead in memory is not large enough to significantly
  slow down the memory operation.

  SRAM doesn't need to be refreshed because it requires four to six transistors,
  compared to the single transistor and capacitor for DRAM; this also means 
  that it's larger and more expensive per bit.

  Dynamic ram is an example of volatile memory, where on power asphyxiation
  the memory is flushed.

EPROM:

  An EPROM is an erasable, programmable, read only memory type; is a type of
  programmable, erasable read only memory.

  This memory can be wiped on exposure to ultraviolet light.

ROM:

  Read only memory; this is an example of immutable memory.

  This type of memory is typically small, fairly small in
  terms of storage, and is immutable, being unable to
  have modifications applied to it through writes operations.

Software:

  NOS:

    A network OS (NOS) is a specialised operating system for a network device, which
    could include things like the Intel Management System, routers and switches.

    Historically, operating systems with network capabilities were described
    by this term, allowing personal computers to access the internet and participate
    in a client server architecture where a server enabled multiple clients to
    share resources, perhaps printing services.

  MUOS:

    A mutli-user operating system allows many users to take advantage of a computer's
    hardware; the operating system must ensure that the requirements of each user are
    balanced.

    It also ensures that the programs being used by them use sufficient
    and separate resources; done so that at problem with one
    user doesn't effect the entire group of users.

    An example of the multi-user design philosophy would be Unix. Allowing remote access
    to the unix shell for various users at the same time.

  RTOS:

    A real time operating system is an operating system that
    guarantees the execution of a task within a fixed time
    constraint; they often ensure the implementation of
    multi tasking, interrupt level sufficiency and multithreading.

  Distributed System:

    A distributed system is a software system in which components
    located on networked computers communicate and coordinate
    their actions by passing messages.

    The components interact with each other in order to achieve a common goal
    across computers; global clock, independent failure of components and a
    lack of a global clock.

  Threading:

    Multithreading is the state of a program's execution where multiple
    execution contexts are involved.

    A thread is an independent instance of a program's execution, having a
    set of distinct values for the processor registers; since this includes
    the instruction register, it controls what it executes. What I mean by
    this is that a thread will naturally have its own execution context.

    It will have a program counter, stack pointer, memory bound, register
    state, the whole lot with respect to it.

    They're the software unit affected by the control flow of the program;
    affected by things operating on the instruction pointer like function
    calls, goto and loops; this is where the term 'thread' comes from,
    because these control flow operations weave the flow execution through
    the program code.

    Without multithreading, a single thread executes the program
    in sequence.

    A thread can be thought of as no more than than a set of register values.

  Operating system (MUOS):

    The operating system has typically three main tasks:

      1. Allocate resources between processes; decide when
         they'll receive CPU time or memory space.

         The operating system will give a fixed
         amount of memory to the processes each
         in order to ensure that one process
         cannot monopolise the computer's
         limited hardware.

         Aside (virtual memory):

          Virtual memory is an abstraction of
          contiguous memory; memory is allocated
          arbitrarily by the operating system's
          memory allocator.

          We often call the virtual memory
          of a program its virtual address space,
          or just simply address space; memory
          that it has access to.

          Aside (memory allocator):

            A memory allocator is typically implemented through
            means of a free list in a fixed-size blocks allocator
            implementation; the free list keeps note
            of what elements are free for use in memory and
            their size. This is typically prone to
            fragmentation, and since the system is inherently
            arbitrary, it only emphasises the R in RAM.
  
            Other implementations may include buddy blocks,
            where in this system allocations of memory
            may be made in several pools as opposed to one.

            Each of the blocks or pools may be a power of two in size;
            each allocation is connected by a linked list
            in the pools for later use, where if a smaller size
            than available is requested, the smallest available size
            is selected and split, the process repeating until
            the request is complete.

      2. Provide an interface for a means of accessing
         the computer's hardware resources; physical memory
         access is an example, virtual memory being
         the abstraction where the interface, in the
         case of the C programming language, is
         the stdlib's malloc and free functions.

      3. Provide common services for interfacing and accessing
         devices; enables applications to be ran
         on different hardware through one common interface.

         This is a generic overview of the second mandated
         feature; two is intrinsically important which is why it
         gets it's own explicit segment.

  Layers to the operating system:

    Operating systems have layers.

    The layered structure mandates that different services
    of the operating system are split into the various
    layers.

    The outer most layer has the user interface
    layer; the inner most layer has the hardware
    layer. A particular layer can access all the
    layers present below it, but not above 
    it; layer n-1 ca access layer n-2 through to
    zero, but cannot access layer n.

    The layers of an operating system are typically
    hardware enforced; the x86 architecture has typically
    four protection rings, where a protection ring is typically
    one or more layers of security.

    They're typically six layers of an operating system
    generally; it may differ depending on the operating
    system.

    1. Hardware layer (second inner most):

    There are various types of devices that we attach to the computer;
    peripheral devices may include the mouse, keyboard, printer, there's
    many I could name; these devices are managed at the hardware layer,
    this layer having the most authority, being attached directly
    to the kernel.

    2.

    CPU scheduling layer:

    The scheduling is managed at this layer of the operating system.
    This is responsible for managing how many processes will be
    allocated to the CPU.

    Note that only one process may be allocated to the CPU at
    any given time; computers swap out these processes really
    quickly to simulate the asyncronisation.

    3. The memory management layer:

    This is concerned with swapping memory in and out; when the computer
    runs, executing programs are allocated to main memory as processes and
    when they finish their purpose they're removed from main memory.

    4. Process management layer:

    The priority of the process is managed within this layer; what priority
    it takes over the CPU's resources.
  
    It's also the place where a process's place on the schedule is determined.

    5. I/o layer:

    I/o buffers are managed in this layer; computer buffers store data
    temporarily, because of the slow operation of I/o devices, storing
    a large amount of data to send it off in one single operation as
    opposed to multiple smaller operations.

    Keyboards typically have buffers attached to them in contexts like
    terminal prompts, such as macro processors for executing commands.

    This is more due to the fact that it's operationally inefficient to
    determine the purpose of a symbol in sequences of characters, and it's
    much easier for the user to determine what they want to tell the shell
    to do if they see the state of the buffer associated to the keyboard.

    Keyboards may not always have a buffer associated to them; in the context
    of text editors like vim, raw mode terminals are used, where input is
    read in a sequence of characters as opposed to buffer dumps.

    In fact, the buffer of a shell gets populated by characters sequentially
    too.

    6. User program layer (outer most):

    This is the layer associated to programs; this is typically the user interface.

    There are two kinds of software, bespoke and suits; bespoke software
    refers to custom built software, being designed to satisfy the
    needs of the one client or perhaps more joint clients, and off the
    shelf software is designed to satisfy the requirements of a large user
    base, only providing features of use to a majority of the customers.

    0. Kernel (inner most layer):

    This is the core part of the computer system and typically
    represents a collective implementation of the operating
    system features that were outlined above.

Firewalls:

  A firewall is a system designed to prevent unauthorised access to and
  from a private network; they can be both hardware and software.

  They're frequently used to prevent unauthorised internet users
  from accessing private networks.

  All messages entering or leaving the intranet (private network)
  pass through the firewall, blocking those that don't meet
  a specified criterion, typically performing a technique called
  packet filtering to ensure that packets entering or leaving the
  network meet a user specified criterion.

Antivirus software:

  A utility that searches a hard disk for viruses are removes any
  that are found; these programs include an auto update feature
  that enabled the program to download profiles of new viruses
  so that it can check for the new viruses as soon as they're 
  discovered.

Advanced Configuration and Power Interface (ACPI):

  This is a power management and configuration standard
  for computers developed by intel, micosoft and toshiba; acpi
  allows the operating system to control the amount of power
  each device is give; for example, to put certain devices
  on standby or power off.

  It can be used to check a variety of things like 
  thermal zones (temperature sensors, fans, the like)
  battery levels, PCI IRQ routing, to name a few.

  Information about the ACPI is stored in the BIOS memory for
  those that support it.

  Segments:

    It comes in two parts; a set of tables
    used for configuration during boot
    and an ACPI runtime environment
    consisting on AML (ACPI Machine Language)
    and the ACPI SSM (System Management Mode).

  To begin using the ACPI the operating system
  must look at the RSDP (Root system directory 
  pointer). If it's found and the verification
  is valid, the operating system
  can access ACPI info through the RSDP pointer.

APIC (Advanced Programmable Interrupt Controller):

  https://wiki.osdev.org/APIC

  This is the standard intel interrupt controller
  specification; it is used for sophisticated
  interrupt redirection and for sending
  interrupts between processors.

  It's part of the ACPI specification.

Interrupt Requests (IRQ):

  https://wiki.osdev.org/Interrupts

  Interrupts are signals from a device, like a keyboard
  or hard drive, to the CPU; they tell the CPU to
  immediately stop whatever it is currently doing and
  to do something else.

  A keyboard controller can send an interrupt when a character key
  is pressed, where the OS can then display the character
  on the screen immediately, regardless of whether or not
  the CPU was doing something before hand.

  A table provided by the operating system will be available to
  the CPU for it to query entries for particular interrupts when
  those specific interrupts occur; in x86 protected mode this
  is called the interrupt descriptor table, and can have up to
  256 entries.

  The name of the table and the number of entries it can hold
  differ depending on the CPU architecture; once the CPU
  finds the entry, it jumps to the code that the entry
  infers to.

  This code is called the interrupt handler, or service routine.

  Three kinds:

    There are three kinds of interrupts, typically.

    1. Exceptions.

      These are generated by the CPU; used to alert the running kernel
      of an event requiring it's attention.

      For x86 CPUs, these includes things like double faults, page faults, general
      protection faults and so on.

    2. Interrupt Requests (Hardware Interrupt).

      These are generated externally by the chipset; signaled by latching onto the
      IRQ pin or equivalent signal of the CPU.

      Interrupt Request Controller (IRQC):

        Wires run from devices on the chipset to an IRQC; this IRQC
        will serialise (convert into an intermediary format) the interrupt
        requests sent by devices.

        This serialised information is typically then transferred to the CPU
        one serialised interrupt datum at a time to prevent race conditions.

        Multithreading with non thread-safe memory access is a good example of
        race conditions, it's also a good excuse to read into multithreading.

        However, the IRQC will in many cases send multiple datums to the CPU at once, based
        on the priority of the device; a very well known IRQC is the Intel 8259 controller
        chain where the Advanced Configuration and Power Interface is a modern version of
        the programmable interrupt controller.
